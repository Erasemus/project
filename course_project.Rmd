---
title: "Practical Machine Learning Project"
author: "Erasemus"
date: "February 20, 2015"
output: html_document
---

This document presents the project for the Coursera class "Practical Machine Learning" sponsored by the Bloomberg School af Health at the Johns Hopkins University and taught by Roger Peng, Brian Caffe and Jeffrey Leek.

This project analyzes data collected as decribed in  
Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements
Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6.

Read more: http://groupware.les.inf.puc-rio.br/work.jsf?p1=10335#ixzz3SLM8kNln
This assignment challenges the student to develop a predictive model for the data which was collected during the performance of specific body postures and movements.  
Approach used to develop a predictive model and perform cross validation:  
1. load the training data  
2. inspect and clean and scale the data, eliminating fields with near zero variance and those with out correlation to the activity (identity of subject, time of measurement , etc.)  
3. create a test partition to cross validate our model for predicting the depndent variable "classe"
4. use random forest as the method for deriving a model  
5. determine the accuracy of the model on the test data partition created in step 3  
6. identify the variables with most impact on the model  
7. revise the data to retain only the most impactful variables    
8. compare the accuracy after the refinement  
9. cross-validate with our test partition  
10. download, clean and subset the official test data in the same way we did the training data
```{r,cache=TRUE}
#get all libraries required up front
library(caret)
library(randomForest)
library(RCurl)

#load the training data
myCsv <- getURL("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
temporaryFile <- tempfile()
con <- file(temporaryFile, open = "w")
cat(myCsv, file = con) 
close(con)
df<-read.csv(temporaryFile)
```
```{r,cache=TRUE}
#df<-read.csv("~/practMachineLearn/pml-training.csv")
# remove variables with little or no variability
df <- df[,-nearZeroVar(df)]
# Remove the columns that, by inspection, add no predictive value
df <- subset(df, select=-c(X,user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp,var_accel_forearm,amplitude_pitch_forearm,min_pitch_forearm,max_picth_forearm,var_yaw_dumbbell,stddev_yaw_dumbbell,avg_yaw_dumbbell,var_pitch_dumbbell,stddev_pitch_dumbbell,avg_pitch_dumbbell,var_roll_dumbbell,stddev_roll_dumbbell,avg_roll_dumbbell,var_accel_dumbbell,amplitude_pitch_dumbbell,amplitude_roll_dumbbell,min_pitch_dumbbell,min_roll_dumbbell,max_picth_dumbbell,max_roll_dumbbell,max_roll_belt,max_picth_belt,min_roll_belt,min_pitch_belt,amplitude_roll_belt,amplitude_pitch_belt,var_total_accel_belt, avg_roll_belt,stddev_roll_belt, var_roll_belt,avg_pitch_belt, stddev_pitch_belt,var_pitch_belt,avg_yaw_belt,stddev_yaw_belt,var_yaw_belt,var_accel_arm,max_picth_arm,max_yaw_arm,min_yaw_arm,amplitude_yaw_arm))
```

create the partitions for training and cross-validation
```{r}
require(caret)
trainingRows <- createDataPartition(df$classe, p = 0.6, list = FALSE)
training <- df[trainingRows,]
CV <- df[-trainingRows,]
```
```{r,cache=TRUE}
# Using the training set above, train a model using RandomForest
#modelFit <- train(classe ~ ., data=training, method="rf", verbose=FALSE)
modelFit<-randomForest(x=training[,1:53],y=training[,54])
```
```{r,cache=TRUE}
preds<-predict(modelFit,CV)
rfCM<-confusionMatrix(preds,CV$classe)
sp <- varImp(modelFit,scale=FALSE)
rfCM
predictors(modelFit)
#sp<-order(sp,decreasing=TRUE)
#print the predictors in order of importance
#print(colnames(training[sp,]))
plot(sp)
```
```{r,cache=TRUE,eval=FALSE}
#Set up the control for Recursive Feature Extraction
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm to compare with varImp and for cross validation
results <- rfe(training[,1:53], training[,54], sizes=c(1:53), rfeControl=control)
# summarize the results
##print(results)
# list the chosen features
predictors(results)
## plot the results
plot(results, type=c("g", "o"))
```
```{r,cache=TRUE}
#
#Set up the control for Recursive Feature Extraction
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm to compare with varImp and for cross validation
results10 <- rfe(training[,1:53], training[,54], sizes=10, rfeControl=control)
# summarize the results
##print(results)
# list the chosen features
predictors(results10)
## plot the results
plot(results10, type=c("g", "o"))
plot.rfe(results10)
str(results10$fit)
summary(results10)
```
```{r,cache=TRUE}
results50 <- rfe(training[,1:53], training[,54], sizes=50, rfeControl=control)
# summarize the results
##print(results)
# list the chosen features
predictors(results50)
## plot the results
plot(results50, type=c("g", "o"))
str(results50$fit)
```
```{r,cache=TRUE}
str(sp)
sp<-order(sp,decreasing=TRUE)
plot(results, metric = "Rsquared")

# summarize importance by sorting then taking the 4 most important variables
osp<-(order(sp,decreasing=TRUE))
#newModelCols<-head(osp,4)
#create new data frames with just the important variables and the outcome
#newMinVarDF<-cbind(training[,newModelCols],training$classe)
#newMinVarCV<-cbind(CV[,newModelCols],CV$classe)
#str(newMinVarDF)
#str(newMinVarCV)
#newModelFit<-randomForest(newMinVarDF[,1-4],y=newMinVarDF$classe)
#summary(newModelFit)
#newPreds<-predict(newModelFit,newMinVarCV)
#str(newPreds)
#str(CV)
#confusionMatrix(newPreds,CV$classe) 
#str(sp)
# plot importance
#plot(sp[,1:53])


