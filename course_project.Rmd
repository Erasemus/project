---
title: "Practical Machine Learning Project"
author: "Erasemus"
date: "March 20, 2015"
output: html_document
---

This document presents the project for the Coursera class "Practical Machine Learning" sponsored by the Bloomberg School af Health at the Johns Hopkins University and taught by Roger Peng, Brian Caffe and Jeffrey Leek.

This project analyzes data collected as decribed in  
Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements
Ugulino, W.; Cardador, D.; Vega, K.; Velloso, E.; Milidiu, R.; Fuks, H. Wearable Computing: Accelerometers' Data Classification of Body Postures and Movements. Proceedings of 21st Brazilian Symposium on Artificial Intelligence. Advances in Artificial Intelligence - SBIA 2012. In: Lecture Notes in Computer Science. , pp. 52-61. Curitiba, PR: Springer Berlin / Heidelberg, 2012. ISBN 978-3-642-34458-9. DOI: 10.1007/978-3-642-34459-6_6.

Read more: http://groupware.les.inf.puc-rio.br/work.jsf?p1=10335#ixzz3SLM8kNln
This assignment challenges the student to develop a predictive model for the data which was collected during the performance of specific body postures and movements.  
Approach used to develop a predictive model and perform cross validation:  
1. load the training data  
2. inspect and clean the data, eliminating fields with near zero variance and those with out correlation to the activity (identity of subject, time of measurement , etc.)  
3. create a test partition to cross validate our model for predicting the dependent variable "classe"
4. use random forest as the method for deriving a model  
5. determine the accuracy of the model via a confusionMatrix on the test data partition created in step 3  
 
{r}
#get all libraries required up front
library(caret)
library(randomForest)
library(RCurl)
```
```{r,cache=TRUE}
#load the training data
myCsv <- getURL("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
temporaryFile <- tempfile()
con <- file(temporaryFile, open = "w")
cat(myCsv, file = con) 
close(con)
df<-read.csv(temporaryFile)
```
```{r,cache=TRUE}
#
# remove variables with little or no variability
#
df <- df[,-nearZeroVar(df)]
#
# Remove the columns that, by inspection, add no predictive value 
# because they have identity data or are NA filled
#
df <- subset(df, select=-c(X,user_name,raw_timestamp_part_1,raw_timestamp_part_2,cvtd_timestamp,var_accel_forearm,amplitude_pitch_forearm,min_pitch_forearm,max_picth_forearm,var_yaw_dumbbell,stddev_yaw_dumbbell,avg_yaw_dumbbell,var_pitch_dumbbell,stddev_pitch_dumbbell,avg_pitch_dumbbell,var_roll_dumbbell,stddev_roll_dumbbell,avg_roll_dumbbell,var_accel_dumbbell,amplitude_pitch_dumbbell,amplitude_roll_dumbbell,min_pitch_dumbbell,min_roll_dumbbell,max_picth_dumbbell,max_roll_dumbbell,max_roll_belt,max_picth_belt,min_roll_belt,min_pitch_belt,amplitude_roll_belt,amplitude_pitch_belt,var_total_accel_belt, avg_roll_belt,stddev_roll_belt, var_roll_belt,avg_pitch_belt, stddev_pitch_belt,var_pitch_belt,avg_yaw_belt,stddev_yaw_belt,var_yaw_belt,var_accel_arm,max_picth_arm,max_yaw_arm,min_yaw_arm,amplitude_yaw_arm))
```
create the partitions for training and cross-validation
```{r}
require(caret)
trainingRows <- createDataPartition(df$classe, p = 0.6, list = FALSE)
training <- df[trainingRows,]
CV <- df[-trainingRows,]
```
```{r,cache=TRUE}
# Using the training set above, train a model using RandomForest
#modelFit <- train(classe ~ ., data=training, method="rf", verbose=FALSE)
modelFit<-randomForest(x=training[,1:53],y=training[,54])
```
```{r,cache=TRUE}
preds<-predict(modelFit,CV)
# use confusion matrix with the cross validation partition to assess the accuracy and 
# the sample error
rfCM<-confusionMatrix(preds,CV$classe)
sp <- varImp(modelFit,scale=FALSE)
rfCM$overall
plot(modelFit)
```
```{r,cache=TRUE,eval=FALSE,echo=FALSE}
#Set up the control for Recursive Feature Extraction
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm to compare with varImp and for cross validation
results <- rfe(training[,1:53], training[,54], sizes=c(1:53), rfeControl=control)
# summarize the results
##print(results)
# list the chosen features
predictors(results)
## plot the results
plot(results, type=c("g", "o"))
```
```{r,cache=TRUE}
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
results50 <- rfe(training[,1:53], training[,54], sizes=50, rfeControl=control)
# summarize the results
##print(results)
# list the chosen features
predictors(results50)
## plot the results
plot(results50, type=c("g", "o"))
str(results50$fit)
```
```{r,cache=TRUE}
str(sp)
sp<-order(sp,decreasing=TRUE)
plot(results50, metric = "Rsquared")

# summarize importance by sorting then taking the 4 most important variables
osp<-(order(sp,decreasing=TRUE))
#newModelCols<-head(osp,4)
#create new data frames with just the important variables and the outcome
#newMinVarDF<-cbind(training[,newModelCols],training$classe)
#newMinVarCV<-cbind(CV[,newModelCols],CV$classe)
#str(newMinVarDF)
#str(newMinVarCV)
#newModelFit<-randomForest(newMinVarDF[,1-4],y=newMinVarDF$classe)
#summary(newModelFit)
#newPreds<-predict(newModelFit,newMinVarCV)
#str(newPreds)
#str(CV)
#confusionMatrix(newPreds,CV$classe) 
#str(sp)
# plot importance
#plot(sp[,1:53])


